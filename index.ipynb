{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Bayesian Statistics - Recap\n", "\n", "## Introduction\n", "\n", "Well done! You covered a lot of ground in this section. From Bayes' theorem to Maximum Likelihood Estimation (MLE), you now have the foundation to dive into the world of Bayesians!\n", "\n", "\n", "\n", "## Bayes' Theorem\n", "\n", "To start, you investigated Bayes' theorem and some hypothetical examples.\n", "\n", "$$ \\large P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)}$$\n", "\n", "\n", "## Bayesian Statistics\n", "\n", "\n", "From there, you then went on to read more about some of the philosophical differences between Bayesians and Frequentists. Bayesians interpret probability as the level of confidence or belief in an event. In contrast, Frequentists view probability as the limit as the number of trials goes to infinity of successes versus trials. \n", "\n", "## MLE and MAP\n", "\n", "In outlining the discussion of Bayesian techniques, you got an introduction to Maximum Likelihood Estimation and Maximum A Posteriori Estimation. In both, you saw methods for optimizing one's beliefs given certain information. This was used to estimate parameters for assumed distributions.\n", "\n", "\n", "## Summary\n", "\n", "Again, quite a bit was covered in this section. There are certainly plenty of additional resources available if you wish to further dive into MLE, MAP, or other Bayesian techniques. Bayesian inference can provide a powerful framework for quantifying and reasoning with uncertainty that has continued to gain popularity with additional computing resources. "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 2}